import math
import json

import tensorflow as tf
import numpy as np
from numpy import dot
from numpy.linalg import norm

from group_fisher import make_group_fisher, add_gates, prune_step, compute_positions, flatten

# path is generated by assiging 2-bit number.
# (0,0,0) -> a path by skipping all layers.
# (1,1,1) -> a sequential path

def decode(encoding_number, group_size):
    decoded = bin(encoding_number)[2:].zfill(group_size)
    print(decoded)

    # edge extraction
    skip_start = None
    path = []
    for k, i in enumerate(decoded):
        #print(k, i, path)
        if i == "0":
            if k == len(decoded)-1:
                if skip_start is None:
                    path.append(k+len(decoded))
                else:
                    path.append((skip_start, k))
                    skip_start = None
            elif skip_start is None:
                skip_start = k

        elif i == "1":
            if skip_start is None:
                path.append(k)
            elif k - skip_start == 1: # single edge path
                path.append((k-1)+len(decoded)) # skip edge is added at the next iteration together.
                path.append(k)
                skip_start = None
            else: # multiple edge path
                path.append((skip_start, k-1))
                path.append(k)
                skip_start = None
        else:
            raise ValueError("decoding error")

    return path

def _traverse(start, nodes, group_size, pset):
    # edge-graph

    stk = [start]
    visited = set()
    visited.add(start)
    while len(stk) > 0:
 
        curr = stk.pop()
        if type(curr) == int:
            end = curr
        else:
            end = curr[1]

        if end == group_size-1 and curr != start:
            return True

        for edge in nodes[curr]["outbounds"]:
            if edge not in visited and edge in pset:
                stk.append(edge)

    return False

def construct_pathset(groups, include):

    psets = []
    for idx, group in enumerate(groups):
        print("idxxxxxxxxxxx ", idx)
        local_inc = include[idx]
        
        paths = []
        for p in local_inc:
            path = decode(p, len(group))
            paths.append(path)

        # merge
        skip_covered = [[] for _ in range(len(group))]
        pset = set()
        psets.append(pset)
        temp = []
        nodes = {}

        print("path", paths)
        exists = set()
        for path in paths:
            for edge in path:
                if type(edge) != tuple: # short edge
                    pset.add(edge)
                    exists.add(edge)
                    if edge > len(group)-1:
                        nodes[edge-len(group)] = {"outbounds":[]}
                        if True not in skip_covered[edge-len(group)]:
                            skip_covered[edge-len(group)].append(True)
                else:
                    temp.append(edge)
                    if edge not in skip_covered[edge[0]]:
                        skip_covered[edge[0]].append(edge)
                    nodes[edge] = {"outbounds":[]}
                    exists.add(edge[1])
           
        print("skip covered", skip_covered)
        # construct conn_graph
        for i in range(len(skip_covered)):
            if i == len(skip_covered)-1:
                continue

            for val in skip_covered[i]:
                if val is True:
                    next_ = i+1
                else:
                    next_ = val[1]+1

                if next_ > len(skip_covered)-1:
                    continue
                assert next_ in exists

                for out in skip_covered[next_]:
                    if out is True:
                        out = next_
                    if val is True:
                        nodes[i]["outbounds"].append(out)
                    else:
                        nodes[val]["outbounds"].append(out)

        print(nodes)
        print(skip_covered)
        temp = sorted(temp, key= lambda x: x[1]-x[0])
        for edge in temp:

            covered_ = False
            for val in skip_covered[edge[0]]:
                if val is True:
                    start = edge[0]
                else:
                    start = val

                    if val[1] > edge[1]:
                        continue

                if start == edge:
                    continue

                print(edge, start, pset)
                if _traverse(start, nodes, len(group), pset):
                    covered_ = True
                    break

            if not covered_:
                pset.add(edge)

    print(psets)
    print(groups)
    return psets

def modify_inbound(layer, add, remove):
    
    assert len(layer["inbound_nodes"]) == 1
    inbound = layer["inbound_nodes"]
    to_remove = []
    for flow in inbound:
        for ib in flow:
            assert type(ib[0]) == str
            if ib[0] in remove:
                to_remove.append(ib)
    for r in to_remove:
        inbound[0].remove(r) # single flow
   
    for a in add:
        a = [a, 0, 0, {}]
        inbound[0].append(a) # single flow

def range_search(parser, start, end):
    ret = []
    for n in parser._graph.nodes:
        if start < parser.torder[n] and parser.torder[n] < end:
            ret.append(n)
    return ret

def replace_input(target_dict, src, dst):
    inbound = target_dict["inbound_nodes"]
    for flow in inbound:
        for ib in flow:
            if ib[0] == src:
                ib[0] = dst

def get_add_inputs(group, edge, layer_dict, parser):
    ret = []
    add = group[edge][0]
    inbound = layer_dict[add]["inbound_nodes"]
    for flow in inbound:
        for ib in flow:
            ret.append(ib[0])

    if parser.torder[ret[0]] > parser.torder[ret[1]]:
        ret.reverse()
    return ret

def evaluate_model(model, custom_objects):
    gmodel, copied_model, l2g, ordered_groups, torder, parser, _ = add_gates(model, custom_objects=custom_objects)
    groups = parser.get_sharing_groups()
    cnt = 0
    for g in groups:
        cnt += pow(model.get_layer(g[0]).filters, len(g))
    return cnt
    
def psets2model(model, groups, psets, parser, custom_objects=None):

    # psets: [{0, 1}, {0, 1}, {(0, 1), 1, 2}, {(0, 1), 1, 2}, {0, 1, 2, 3, 5}]
    # groups: [[('block2b_add', 51, [('block2b_drop', 50), ('block2a_project_bn', 34)])], [('block3b_add', 83, [('block3b_drop', 82), ('block3a_project_bn', 66)])], [('block4b_add', 115, [('block4b_drop', 114), ('block4a_project_bn', 98)]), ('block4c_add', 132, [('block4c_drop', 131), ('block4b_add', 115)])], [('block5b_add', 164, [('block5b_drop', 163), ('block5a_project_bn', 147)]), ('block5c_add', 181, [('block5c_drop', 180), ('block5b_add', 164)])], [('block6b_add', 213, [('block6b_drop', 212), ('block6a_project_bn', 196)]), ('block6c_add', 230, [('block6c_drop', 229), ('block6b_add', 213)]), ('block6d_add', 247, [('block6d_drop', 246), ('block6c_add', 230)])]]

    conn_to = {}
    for g in groups:
        for item in g:
            add_name = item[0]
            node = parser.get_nodes([add_name])[0]
            neighbors = parser._graph.out_edges(node[0], data=True)

            conn_to[add_name] = []
            for n in neighbors:
                conn_to[add_name].append(n[1])

    model_dict = json.loads(model.to_json())
    layer_dict = {}
    for layer in model_dict["config"]["layers"]:
        layer_dict[layer["name"]] = layer

    removed_layers = []
    alive_layers = []
    for group, pset in zip(groups, psets):
        print(group, pset)
        for idx in range(len(group)):
            add_name = group[idx][0]
            print(add_name)
            body = False
            skip = False
            jumping = []
            print("pset", pset)
            for p in pset:
                if type(p) != tuple:
                    print(idx, p, len(group))
                    if idx == p:
                        body = True
                    elif p > len(group)-1 and idx == p-len(group):
                        skip = True
                else:
                    if p[-1] == idx:
                        jumping.append(p)

            a = None
            b = None
            for ib in layer_dict[add_name]["inbound_nodes"]:
                a = ib[0][0]
                b = ib[1][0]

                if parser.torder[a] > parser.torder[b]:
                    temp = a
                    a = b
                    b = temp

                break # assume unique flow.

            if int(body) + int(skip) + len(jumping) > 1: # not erase add
                add_layer = layer_dict[add_name]
                remove = []
                if not body:
                    remove.append(b)
                    removed_layers += range_search(parser, parser.torder[a], parser.torder[add_name])
                else:
                    old_a = group[idx][2][0][0]
                    if old_a == b:
                        old_a = group[idx][2][1][0]
                    print("???", old_a, add_name)
                    alive_layers += range_search(parser, parser.torder[old_a], parser.torder[add_name])

                    #if a in [x[0] for x in group[idx][2]]:
                    #    alive_layers += range_search(parser, parser.torder[a]-1, parser.torder[add_name])
                if not skip:
                    remove.append(a)

                add = []
                for jump in jumping:
                    sour = jump[0]
                    ret = get_add_inputs(group, sour, layer_dict, parser) # return sour's inputs
                    add.append(ret[0])

                modify_inbound(add_layer, add, remove)

                print("here1", removed_layers)

            elif int(body) + int(skip) + len(jumping) == 1:
                removed_layers.append(add_name)

                print("here2")
                target_dicts = [ layer_dict[conn] for conn in conn_to[add_name] ]
                if body:
                    print("xx_body ", b, parser.torder[a], parser.torder[b])
                    for target_dict in target_dicts:
                        replace_input(target_dict, add_name, b)
                        print(target_dict)
                    print(a, b, group[idx][2])
                    old_a = group[idx][2][0][0]
                    if old_a == b:
                        old_a = group[idx][2][1][0]
                    alive_layers += range_search(parser, parser.torder[old_a], parser.torder[add_name])
                elif skip:
                    print("xx_skip ", a)
                    for target_dict in target_dicts:
                        replace_input(target_dict, add_name, a)
                    removed_layers += range_search(parser, parser.torder[a], parser.torder[add_name])
                else: #jumping
                    jump = jumping[0]
                    sour = jump[0]
                    ret = get_add_inputs(group, sour, layer_dict, parser) # return sour's inputs
                    for target_dict in target_dicts:
                        replace_input(target_dict, add_name, ret[0])
                    removed_layers += range_search(parser, parser.torder[a], parser.torder[add_name])

                print(add_name)
                print(target_dicts)

            else:
                print("here3")
                removed_layers.append(add_name)
                removed_layers += range_search(parser, parser.torder[a], parser.torder[add_name])

                target_dicts = [ layer_dict[conn] for conn in conn_to[add_name] ]

                ret = get_add_inputs(group, 0, layer_dict, parser) # return sour's inputs
                for target_dict in target_dicts:
                    replace_input(target_dict, add_name, ret[0])
   
    removed = list()
    print("removed", removed_layers)
    print("alive", alive_layers)
    for r in removed_layers:
        if r in alive_layers:
            continue
        if layer_dict[r] in model_dict["config"]["layers"] :
            model_dict["config"]["layers"].remove(layer_dict[r])
        removed.append(layer_dict[r])

    model_json = json.dumps(model_dict)
    cmodel = tf.keras.models.model_from_json(model_json, custom_objects=custom_objects)

    for layer in cmodel.layers:
        layer.set_weights(model.get_layer(layer.name).get_weights())

    return cmodel


def eval_(model, cmodel, data):

    """
    avg_err = 0
    cnt = 0
    for x in data:
        y1 = model(x[0])
        y2 = cmodel(x[0])

        avg_err += np.sum(np.linalg.norm(y2-y1, ord=2, axis=-1))
        cnt += 1
    """

    avg_err = 0
    cnt = 0
    for x1,x2 in zip(data[:len(data)//2], data[len(data)//2:]):
        y11 = model(x1[0])
        y12 = model(x2[0])

        y21 = cmodel(x1[0])
        y22 = cmodel(x2[0])

        a = y11-y12
        b = y21-y22

        cos_dist = 0
        for a_, b_ in zip(a, b):
            cos_dist += 1-dot(a_, b_)/(norm(a_)*norm(b_))

        avg_err += cos_dist / a.shape[0]

        cnt += 1

    return float(avg_err) / cnt

def evaluate(model, groups, parser, datagen, custom_objects=None):

    data_keep = []
    for k, data in enumerate(datagen):
        data_keep.append(data)
        if k == 100:
            break


    """
    curr_include = [[1, 0], [1], [0, 3], [0], [0, 1, 7, 2]]
    curr_include = [[0, 1], [1, 0], [0, 1], [0, 2, 3, 1], [0, 4, 2, 5, 1, 3]]
    curr_include = [[0, 1], [1, 0], [0, 1], [0, 2, 3, 1], [0, 4, 2, 5, 3]]
    curr_include = [[], [], [], [], [], [4], []]
    curr_include = [[0, 1], [0, 1], [], [], [], [], []]
    curr_include = [[0, 1], [0, 2, 1, 3], [0, 1, 2, 3], [0, 4, 2, 5, 1], [1], [], []]
    curr_include = [[0], [0], [0], [0], [0, 4, 2, 6]]

    psets = construct_pathset(groups, curr_include)

    cmodel = psets2model(model, groups, psets, parser, custom_objects)
    return cmodel
    """

    curr_include = [[0] for _  in range(len(groups))]
    #history = [(4, 4), (4, 2), (3, 1), (4, 5), (1, 1), (3, 2), (2, 2), (0, 1), (2, 1), (2, 3)] # base greedy
    #history = [(4, 4), (4, 2), (4, 5), (3, 2), (1, 1), (2, 2), (3, 1), (0, 1), (2, 1), (2, 3)]
    history = [(4, 4), (3, 1), (4, 2), (1, 1), (4, 5), (2, 2), (3, 2), (0, 1), (2, 1), (2, 3)]
    
    for i, (k, g) in enumerate(history):
        print("**************", float(i) / len(history))
        if  0.1 < float(i) / len(history) :
            break
        curr_include[k].append(g)

    print("++++++", curr_include)
    psets = construct_pathset(groups, curr_include)
    print(psets)
    cmodel = psets2model(model, groups, psets, parser, custom_objects)
    err = eval_(model, cmodel, data_keep)
    print(err)

    from keras_flops import get_flops
    flops = get_flops(cmodel, batch_size=1)
    print(f"FLOPS: {flops / 10 ** 9:.06} G")

    from profile import measure

    x = measure(model, "onnx_cpu")
    y = measure(cmodel, "onnx_cpu")

    print(x, y)

    return cmodel

    """
    curr_include = [[] for _  in range(len(groups))]
    history = [(0, 0), (3, 0), (0, 1), (3, 1), (2, 2), (2, 1), (2, 3), (4, 0), (2, 0), (3, 2), (4, 6), (4, 7), (4, 3), (4, 5), (1, 0)]

    for k, g in history:
        curr_include[k].append(g)
    psets = construct_pathset(groups, curr_include)
    cmodel = psets2model(model, groups, psets, parser, custom_objects)
    err = eval_(model, cmodel, data_keep)
    best_val = err
    """

    original_cnt = evaluate_model(model, custom_objects)
    curr_include = [[0] for _  in range(len(groups))]
    history = []
    for i in range(10):
        print(i)
        best_val = None
        best = None
        for k, group in enumerate(groups):
            for g in range(pow(2, len(group))):
                if g in curr_include[k]:
                    continue

                curr_include[k].append(g)
                print("++++++++++", curr_include)
                psets = construct_pathset(groups, curr_include)
                cmodel = psets2model(model, groups, psets, parser, custom_objects)

                curr_include[k].pop()
   
                err = eval_(model, cmodel, data_keep)
                #changed_cnt = evaluate_model(cmodel, custom_objects)
                #err_ = err
                #err = (2.0-changed_cnt / original_cnt) * err

                #print(err, (2-changed_cnt / original_cnt), err_, best_val)
                print(err, best_val)
                if best_val is None or best_val > err:
                    best_val = err
                    best = (k, g)

        curr_include[best[0]].append(best[1])
        history.append(best)

    print("final:", curr_include)
    print("history:", history)
    psets = construct_pathset(groups, curr_include)
    print(psets)
    cmodel = psets2model(model, groups, psets, parser, custom_objects)
    return cmodel


def rewire(datagen, model, parser, custom_objects=None):

    tf.keras.utils.plot_model(model, "omodel.pdf", show_shapes=True)
    # parse
    model_dict = json.loads(model.to_json())
    groups = []
    group = None
    for layer in model_dict["config"]["layers"]:
        if layer["class_name"] == "Add":
            left = None
            right = None
            for ib in layer["inbound_nodes"]:
                left = model.get_layer(ib[0][0])
                right = model.get_layer(ib[1][0])

                if left.__class__.__name__ != "Add" and right.__class__.__name__ != "Add": # start group
                    group = [] # assign new group
                    groups.append(group)

                pair = [(left.name, parser.torder[left.name]), (right.name, parser.torder[right.name])]

                assert len(ib) == 2
            assert len(layer["inbound_nodes"]) == 1
            group.append((layer["name"], parser.torder[layer["name"]], pair))

    # groups 
    #   - group
    #       - (add_layer_name, add_layer_torder, pair) ...
    #           - pair: [(left, left_tordr), (right, right_torder)]
    cmodel = evaluate(model, groups, parser, datagen, custom_objects)
    #tf.keras.utils.plot_model(model, "model.pdf", show_shapes=True)


    tf.keras.utils.plot_model(cmodel, "model.pdf", show_shapes=True)
    tf.keras.models.save_model(cmodel, "rewire.h5")

    print(model.summary())
    print(cmodel.summary())

    """
    from keras_flops import get_flops
    flops = get_flops(model, batch_size=1)
    print(f"FLOPS: {flops / 10 ** 9:.06} G")

    flops = get_flops(cmodel, batch_size=1)
    print(f"FLOPS: {flops / 10 ** 9:.06} G")

    from profile import measure

    x = measure(model, "onnx_cpu")
    y = measure(cmodel, "onnx_cpu")

    print(x, y)
    """
     
    return model

def apply_rewiring(train_data_generator, teacher, gated_model, groups, l2g, parser, target_ratio, save_dir, save_prefix, save_steps, custom_objects=None):

    rewire(train_data_generator, teacher, parser, custom_objects)


    xxx


